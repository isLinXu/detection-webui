# vision-process-webui

![](https://user-images.githubusercontent.com/59380685/265589543-e255edad-11a9-4be4-8a8d-870dcd00cc08.png)

![GitHub watchers](https://img.shields.io/github/watchers/isLinXu/vision-process-webui.svg?style=social) ![GitHub stars](https://img.shields.io/github/stars/isLinXu/vision-process-webui.svg?style=social) ![GitHub forks](https://img.shields.io/github/forks/isLinXu/vision-process-webui.svg?style=social) ![GitHub followers](https://img.shields.io/github/followers/isLinXu.svg?style=social)
[![Build Status](https://img.shields.io/endpoint.svg?url=https%3A%2F%2Factions-badge.atrox.dev%2Fatrox%2Fsync-dotenv%2Fbadge&style=flat)](https://github.com/isLinXu/vision-process-webui)  ![img](https://badgen.net/badge/icon/learning?icon=deepscan&label)![GitHub repo size](https://img.shields.io/github/repo-size/isLinXu/vision-process-webui.svg?style=flat-square) ![GitHub language count](https://img.shields.io/github/languages/count/isLinXu/vision-process-webui)  ![GitHub last commit](https://img.shields.io/github/last-commit/isLinXu/vision-process-webui) ![GitHub](https://img.shields.io/github/license/isLinXu/vision-process-webui.svg?style=flat-square)![img](https://hits.dwyl.com/isLinXu/vision-process-webui.svg)

**language**: [en ÔΩú [‰∏≠Êñá](README_zh.md)]

---

# üé§Introduction

Due to the increasing complexity of the theory and models of computer vision, in order to facilitate intuitive understanding and reproduction, 
reduce the threshold of use, and quickly verify image processing effects, inspired by the stable-diffusion-webui project in the promotion of the stable-diffusion model application, 
some models based on tasks such as object detection, image segmentation, and image classification are deployed and demonstrated on Gradio for inference.
More people are welcome to contribute and use!

# üõúOnline running

- ‚ùóÔ∏èCurrently, the app application of this repository has been deployed on ![Open in OpenXLab](https://cdn-static.openxlab.org.cn/app-center/openxlab_app.svg)[**OpenXLab**](https://openxlab.org.cn/apps),![Open in ModelScope](https://badgen.net/badge/icon/modelscope?icon=deepscan&label)[**ModelScope**](https://www.modelscope.cn/studios) and [<img src="https://user-images.githubusercontent.com/59380685/266578643-982c5416-1c5f-4b50-ba0a-ed11e8708df5.png" style="zoom:50%;" />]()[**huggingface**](https://huggingface.co/). Welcome to test and use.

## OpenMMLab
- [x] üì¶[**MMYOLO**]():[![Open in OpenXLab](https://cdn-static.openxlab.org.cn/app-center/openxlab_app.svg)](https://openxlab.org.cn/apps/detail/gatilin/mmyolo-webui)
- [x] üì¶[**MMDetection**]():[![Open in OpenXLab](https://cdn-static.openxlab.org.cn/app-center/openxlab_app.svg)](https://openxlab.org.cn/apps/detail/gatilin/mmdetection-webui)
- [ ] üì¶[**MMDetection3D**]():
- [ ] üì¶[**MMSegmentation**]():
- [ ] üì¶[**MMOCR**]():
- [ ] üì¶[**MMHuman3D**]():
- [ ] üì¶[**MMAction2**]():
- [ ] üì¶[**MMTracking**]():
- [x] üì¶[**MMPreTrain**]():[![Open in OpenXLab](https://cdn-static.openxlab.org.cn/app-center/openxlab_app.svg)](https://openxlab.org.cn/apps/detail/gatilin/mmpretrain-webui)
- [x] üì¶[**MMPose**]():[![Open in OpenXLab](https://cdn-static.openxlab.org.cn/app-center/openxlab_app.svg)](https://openxlab.org.cn/apps/detail/gatilin/mmpose-webui)
- [ ] üì¶[**MMagic**]():
- [ ] üì¶[**MMGeneration**]():
- [ ] üì¶[**MMEditing**]():
- [ ] üì¶[**MMFlow**]():
- [ ] üì¶[**MMRazor**]():
- [ ] üì¶[**MMFewShot**]():


## detection
- [x] üì¶[**yolov8-app**]():[![Open in OpenXLab](https://cdn-static.openxlab.org.cn/app-center/openxlab_app.svg)](https://openxlab.org.cn/apps/detail/gatilin/yolov8-webui)[![Open in ModelScope](https://badgen.net/badge/icon/modelscope?icon=deepscan&label)](https://www.modelscope.cn/studios/isLinXu/yolov8-webui/summary)[<img src="https://user-images.githubusercontent.com/59380685/266578643-982c5416-1c5f-4b50-ba0a-ed11e8708df5.png" style="zoom:50%;" />](https://huggingface.co/spaces/gatilin/yolov8-webui)
- [x] üì¶[**yolov5-app**]():[![Open in OpenXLab](https://cdn-static.openxlab.org.cn/app-center/openxlab_app.svg)](https://openxlab.org.cn/apps/detail/gatilin/yolov5-webui)[![Open in ModelScope](https://badgen.net/badge/icon/modelscope?icon=deepscan&label)](https://www.modelscope.cn/studios/isLinXu/yolov5-webui/summary)[<img src="https://user-images.githubusercontent.com/59380685/266578643-982c5416-1c5f-4b50-ba0a-ed11e8708df5.png" style="zoom:50%;" />](https://huggingface.co/spaces/gatilin/yolov5-webui)
- [x] üì¶[**yolov3-app**]():[![Open in OpenXLab](https://cdn-static.openxlab.org.cn/app-center/openxlab_app.svg)](https://openxlab.org.cn/apps/detail/gatilin/yolov3-webui)[![Open in ModelScope](https://badgen.net/badge/icon/modelscope?icon=deepscan&label)](https://www.modelscope.cn/studios/isLinXu/yolov3-webui/summary)[<img src="https://user-images.githubusercontent.com/59380685/266578643-982c5416-1c5f-4b50-ba0a-ed11e8708df5.png" style="zoom:50%;" />](https://huggingface.co/spaces/gatilin/yolov3-webui)
- [x] üì¶[**yolox-app**]():[![Open in OpenXLab](https://cdn-static.openxlab.org.cn/app-center/openxlab_app.svg)](https://openxlab.org.cn/apps/detail/gatilin/yolox-webui)[![Open in ModelScope](https://badgen.net/badge/icon/modelscope?icon=deepscan&label)](https://www.modelscope.cn/studios/isLinXu/yolox-webui/summary)
- [x] üì¶[**yolonas-app**]():[![Open in OpenXLab](https://cdn-static.openxlab.org.cn/app-center/openxlab_app.svg)](https://openxlab.org.cn/apps/detail/gatilin/yolonas-webui)[![Open in ModelScope](https://badgen.net/badge/icon/modelscope?icon=deepscan&label)](https://www.modelscope.cn/studios/isLinXu/yolonas-webui/summary)
- [x] üì¶[**ppyoloe-app**]():[![Open in OpenXLab](https://cdn-static.openxlab.org.cn/app-center/openxlab_app.svg)](https://openxlab.org.cn/apps/detail/gatilin/ppyoloe_webui)[![Open in ModelScope](https://badgen.net/badge/icon/modelscope?icon=deepscan&label)](https://www.modelscope.cn/studios/isLinXu/ppyoloe-webui/summary)
- [x] üì¶[**torchvision-detection-webui**]():[![Open in OpenXLab](https://cdn-static.openxlab.org.cn/app-center/openxlab_app.svg)](https://openxlab.org.cn/apps/detail/gatilin/torchvision-detection-webui)[![Open in ModelScope](https://badgen.net/badge/icon/modelscope?icon=deepscan&label)](https://www.modelscope.cn/studios/isLinXu/torchvision-detection-webui/summary)

## classification
- [x] üì¶[**torchvision-classification-app**]():[![Open in OpenXLab](https://cdn-static.openxlab.org.cn/app-center/openxlab_app.svg)](https://openxlab.org.cn/apps/detail/gatilin/torchvision-classification-webui#build-configuration)[![Open in ModelScope](https://badgen.net/badge/icon/modelscope?icon=deepscan&label)](https://www.modelscope.cn/studios/isLinXu/torchvision-cls-app/summary)
- [x] üì¶[**timm-classification-webui**]():[![Open in OpenXLab](https://cdn-static.openxlab.org.cn/app-center/openxlab_app.svg)](https://openxlab.org.cn/apps/detail/gatilin/timm-classification-webui)[![Open in ModelScope](https://badgen.net/badge/icon/modelscope?icon=deepscan&label)](https://www.modelscope.cn/studios/isLinXu/timm-classification-webui/summary)

## segmentation
- [x] üì¶[**torchvision-segmentation-app**]():[![Open in OpenXLab](https://cdn-static.openxlab.org.cn/app-center/openxlab_app.svg)](https://openxlab.org.cn/apps/detail/gatilin/torchvision-segmention-webui)[![Open in ModelScope](https://badgen.net/badge/icon/modelscope?icon=deepscan&label)](https://www.modelscope.cn/studios/isLinXu/timm-classification-webui/summary)
- [x] üì¶[**mobile-sam-app**]():[![Open in OpenXLab](https://cdn-static.openxlab.org.cn/app-center/openxlab_app.svg)](https://openxlab.org.cn/apps/detail/gatilin/mobile-sam-webui)[![Open in ModelScope](https://badgen.net/badge/icon/modelscope?icon=deepscan&label)](https://www.modelscope.cn/studios/isLinXu/mobile_sam_webui/summary)

# üßôperformance&demo

## üî®OpenMMLab

| [![](https://user-images.githubusercontent.com/59380685/266564924-9bf09e70-9c3c-4970-9d99-91b8409e95d3.png)](https://openxlab.org.cn/apps/detail/gatilin/mmpretrain-webui) | [![](https://user-images.githubusercontent.com/59380685/266564614-9a6a296c-cdf5-4d11-9458-49501d88f1bc.png)](https://openxlab.org.cn/apps/detail/gatilin/mmyolo-webui) | [![](https://user-images.githubusercontent.com/59380685/266564542-3b198cfd-6aa0-4676-8b4e-12a0f8c04de9.png)](https://openxlab.org.cn/apps/detail/gatilin/mmdetection-webui) | [![](https://user-images.githubusercontent.com/59380685/266565159-831cc038-a841-4c53-9503-42daf78fcea2.png)](https://openxlab.org.cn/apps/detail/gatilin/mmpose-webui) |
|:--------------------------------------------------------------------------------------------------------------:|:--------------------------------------------------------------------------------------------------------------:|:--------------------------------------------------------------------------------------------------------------:|:--------------------------------------------------------------------------------------------------------------:|
|                           [**MMPreTrain**](https://github.com/open-mmlab/mmpretrain)                           |                               [**MMYOLO**](https://github.com/open-mmlab/mmyolo)                               |                          [**MMDetection**](https://github.com/open-mmlab/mmdetection)                          |                               [**MMPose**](https://github.com/open-mmlab/mmpose)                               |
|                                                                                                                |                                                                                                                |                                                                                                                |                                                                                                                |
|                                                                                                                |                                                                                                                |                                                                                                                |                                                                                                                |


## üî®classification
| ![](https://user-images.githubusercontent.com/59380685/265667039-ce3f2122-4317-4c57-9bab-9ebc792ca23b.png) |
| ------------------------------------------------------------ |
| ![](https://user-images.githubusercontent.com/59380685/265667095-6a0d4513-cb21-42ff-b77c-723da474d0fe.png) |
| ![](https://user-images.githubusercontent.com/59380685/265667360-20438bef-91ee-4847-a5e2-16ef4e658935.png) |

---

## üî®detection
| ![](https://user-images.githubusercontent.com/59380685/265492490-9353cd87-052d-4dcb-9115-afb7954c00dd.png) | ![](https://user-images.githubusercontent.com/59380685/265493664-939d5c5f-f571-4a84-b6e9-6193f4613f37.png) | ![](https://user-images.githubusercontent.com/59380685/265493715-e920d82e-c85d-43e1-a7ae-c0a706c0bb95.png) | ![](https://user-images.githubusercontent.com/59380685/265493821-19954089-befb-4cec-baac-688427a84589.png) |
| :----------------------------------------------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: |
|                          YOLOv8-det                          |                          YOLOv8-seg                          |                          YOLOv8-seg                          |                          YOLOv8-seg                          |



| ![](https://user-images.githubusercontent.com/59380685/265312963-41d535a2-f920-443e-a048-6428983fac46.png) | ![](https://user-images.githubusercontent.com/59380685/265313403-9e4937bc-a497-4806-ab9c-99a3b864f2d9.png) | ![](https://user-images.githubusercontent.com/59380685/265313486-6a3785ee-0202-4a4f-9816-23dbb0a3588c.png) |
| :----------------------------------------------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: |
|                                                              |                                                              |                                                              |
|                                                              |                                                              |                                                              |
|                            YOLOv3                            |                            YOLOv5                            |                            YOLOX                             |
| ![](https://user-images.githubusercontent.com/59380685/265494398-e053e543-11ec-4fc7-81ad-32bb97983fc0.png) | ![](https://user-images.githubusercontent.com/59380685/265494778-5262fb37-40f2-46df-b31e-089775d9223c.png) | ![](https://user-images.githubusercontent.com/59380685/265507024-baa0f476-4800-4bba-9129-5e2744468495.png) |
|                           YOLO-NAS                           |                           PP-YOLOE                           |                           RT-Detr                            |

---

## üî®segmentation
| [![](https://user-images.githubusercontent.com/59380685/265508535-ce1820d2-e161-4ddf-bd7a-70c5306ee5d5.png)]() | ![](https://user-images.githubusercontent.com/59380685/265508607-9c07e74c-a083-4df7-bd31-38d1bb402b25.png) |
|:--------------------------------------------------------------------------------------------------------------:| :----------------------------------------------------------: |
|   ![](https://user-images.githubusercontent.com/59380685/265508557-bc5baa23-f5a0-408e-88b6-c112f9891dd8.png)   | ![](https://user-images.githubusercontent.com/59380685/265508693-189b0990-149a-4fe6-bada-bb8ae7c09042.png) |
|                                               mobile-sam[point]                                                |                       mobile-sam[bbox]                       |

---

# üÜïNews
- [x] (2023-09-08): `mmyolo„ÄÅmmpretrain„ÄÅmmdetection„ÄÅmmpose`
- [x] (2023-09-07): `yolov3„ÄÅyolov5„ÄÅyolov8„ÄÅyolo_nas„ÄÅyolox„ÄÅtorchvision-detection„ÄÅmobile-sam„ÄÅtimm-classification`
- [x] (2023-09-02): repo init.

# üóìsupport list

## üî®classification

- [x] **VGG16**([src](https://arxiv.org/abs/1409.1556) | [code](webui/cls/torchvision_cls_ui.py))
- [x] **AlexNet**([src](https://arxiv.org/abs/1404.5997) | [code](webui/cls/torchvision_cls_ui.py))
- [x] **ResNet18**([src](https://arxiv.org/abs/1512.03385) | [code](webui/cls/torchvision_cls_ui.py))
- [x] **ResNet50**([src](https://arxiv.org/abs/1512.03385) | [code](webui/cls/torchvision_cls_ui.py))
- [x] **ResNet101**([src](https://arxiv.org/abs/1512.03385) | [code](webui/cls/torchvision_cls_ui.py))
- [x] **ResNet152**([src](https://arxiv.org/abs/1512.03385) | [code](webui/cls/torchvision_cls_ui.py))
- [x] **GoogLeNet**([src](https://arxiv.org/abs/1409.4842) | [code](webui/cls/torchvision_cls_ui.py))
- [x] **DenseNet121**([src](https://arxiv.org/abs/1608.06993) | [code](webui/cls/torchvision_cls_ui.py))
- [x] **MobileNetV2**([src](https://arxiv.org/abs/1801.04381) | [code](webui/cls/torchvision_cls_ui.py))
- [x] **SqueezeNet**([src]() | [code](webui/cls/torchvision_cls_ui.py))
- [x] **WideResNet50**([src]() | [code](webui/cls/torchvision_cls_ui.py))
- [x] **WideResNet101**([src]() | [code](webui/cls/torchvision_cls_ui.py))
- [x] **InceptionV3**([src]() | [code](webui/cls/torchvision_cls_ui.py))

## üî®detection

- [x] **yolov3**([src](https://docs.ultralytics.com/models/yolov3/) | [code](webui/det/yolov3_ui.py))
- [ ] **yolov4**([src](https://docs.ultralytics.com/models/yolov4/) | [code](webui/det/yolov4_ui.py))
- [x] **yolov5**([src](https://docs.ultralytics.com/models/yolov5/) | [code](webui/det/yolov5_ui.py))
- [ ] **yolov6**([src](https://docs.ultralytics.com/models/yolov6/) | [code](webui/det/yolov6_ui.py))
- [ ] **yolov7**([src](https://docs.ultralytics.com/models/yolov7/) | [code](webui/det/yolov7_ui.py))
- [x] **yolox**([src](https://github.com/Deci-AI/super-gradients/blob/master/src/super_gradients/training/models/detection_models/yolox.py) | [code](webui/det/yolox_ui.py)))
- [x] **ppyoloe**([src](https://github.com/Deci-AI/super-gradients/tree/master/src/super_gradients/training/models/detection_models/pp_yolo_e) | [code](webui/det/ppyoloe_ui.py)))
- [x] **yolo-nas**([src](https://github.com/Deci-AI/super-gradients/blob/master/YOLONAS.md) | [code](webui/det/yolonas_ui.py)))
- [x] **yolov8**([src](https://docs.ultralytics.com/models/yolov8/) | [code](webui/det/yolov8_ui.py))
- [x] **rtdetr-l**([src](https://docs.ultralytics.com/models/rtdetr/) | [code](webui/det/rt_detr_ui.py)))
- [x] **fasterrcnn_resnet50_fpn**([src]() | [code](webui/det/torchvision_det_ui.py)))
- [x] **maskrcnn_resnet50_fpn**([src]() | [code](webui/det/torchvision_det_ui.py)))
- [x] **keypointrcnn_resnet50_fpn**([src]() | [code](webui/det/torchvision_det_ui.py)))
- [x] **retinanet_resnet50_fpn**([src]() | [code](webui/det/torchvision_det_ui.py)))
---

## üî®segmentation

- [x] **mobile_sam**([src](https://docs.ultralytics.com/models/mobile-sam/) | [code](webui/seg/mobilesam_ui.py))
- [x] **fast_sam**([src](https://docs.ultralytics.com/models/fast-sam/) | [code](webui/seg/fastsam_ui.py))
- [x] **DeepLabv3**([src]() | [code](webui/seg/torchvision_seg_ui.py))
- [x] **DeepLabv3+**([src]() | [code](webui/seg/torchvision_seg_ui.py))
- [x] **FCN-ResNet50**([src]() | [code](webui/seg/torchvision_seg_ui.py))
- [x] **FCN-ResNet101**([src]() | [code](webui/seg/torchvision_seg_ui.py))
- [x] **LRR**([src]() | [code](webui/seg/torchvision_seg_ui.py))
- [ ] UNet()

# üìñUsage

## 1. install
```shell
git clone https://github.com/isLinXu/vision-process-webui.git
cd vision-process-webui
pip install -r requirements.txt
```

## 2. download weights
```shell
cd weights
cd [model_name]
sh download_weights.sh
```
model_name=xxxx


## 3. run
```shell
python webui/model_app.py
```
model_app=classification|detection|segmentation
or

```shell
cd webui/app
python [model_app].py
```
model_app=yolov3|yolov5|yolov8|yolonas|ppyoloe|torchvision-detection|torchvision-classification|torchvision-segmentation|mobile-sam|fast-sam


# üßæTODO
## support more models and libraries
- [x] üì¶[**MMYOLO**]()
- [x] üì¶[**MMDetection**]()
- [ ] üì¶[**MMDetection3D**]():
- [ ] üì¶[**MMSegmentation**]():
- [ ] üì¶[**MMOCR**]():
- [ ] üì¶[**MMHuman3D**]():
- [ ] üì¶[**MMAction2**]():
- [ ] üì¶[**MMTracking**]():
- [x] üì¶[**MMPreTrain**]():
- [x] üì¶[**MMPose**]():
- [ ] üì¶[**MMagic**]():
- [ ] üì¶[**MMagic**]():
- [ ] üì¶[**MMGeneration**]():
- [ ] üì¶[**MMEditing**]():
- [ ] üì¶[**MMFlow**]():
- [ ] üì¶[**MMRazor**]():
- [ ] üì¶[**MMFewShot**]():

## docker image build
- pass

## merge all ui.py in one
- pass


# üå∏Reference
- [**stable-diffusion-webui**](https://github.com/AUTOMATIC1111/stable-diffusion-webui): Stable Diffusion web UI
- [**torchvision**](https://github.com/pytorch/vision): Datasets, Transforms and Models specific to Computer Vision
- [**timm**](https://github.com/huggingface/pytorch-image-models): PyTorch image models, scripts, pretrained weights -- ResNet, ResNeXT, EfficientNet, NFNet, Vision Transformer (ViT), MobileNet-V3/V2, RegNet, DPN, CSPNet, Swin Transformer, MaxViT, CoAtNet, ConvNeXt, and more
- [**yolov3**](https://github.com/ultralytics/yolov3): YOLOv3 in PyTorch > ONNX > CoreML > TFLite
- [**yolov5**](https://github.com/ultralytics/yolov5): YOLOv5 üöÄ in PyTorch > ONNX > CoreML > TFLite
- [**ultralytics**](https://github.com/ultralytics/ultralytics): NEW - YOLOv8 üöÄ in PyTorch > ONNX > OpenVINO > CoreML > TFLite
- [**super-gradients**](https://github.com/Deci-AI/super-gradients): Easily train or fine-tune SOTA computer vision models with one open source training library. The home of Yolo-NAS.
- [**MMEngine**](https://github.com/open-mmlab/mmengine): OpenMMLab foundational library for training deep learning models.
- [**MMCV**](https://github.com/open-mmlab/mmcv): OpenMMLab foundational library for computer vision.
- [**MMPreTrain**](https://github.com/open-mmlab/mmpretrain): OpenMMLab pre-training toolbox and benchmark.
- [**MMagic**](https://github.com/open-mmlab/mmagic): Open**MM**Lab **A**dvanced, **G**enerative and **I**ntelligent **C**reation toolbox.
- [**MMDetection**](https://github.com/open-mmlab/mmdetection): OpenMMLab detection toolbox and benchmark.
- [**MMDetection3D**](https://github.com/open-mmlab/mmdetection3d): OpenMMLab's next-generation platform for general 3D object detection.
- [**MMRotate**](https://github.com/open-mmlab/mmrotate): OpenMMLab rotated object detection toolbox and benchmark.
- [**MMYOLO**](https://github.com/open-mmlab/mmyolo): OpenMMLab YOLO series toolbox and benchmark.
- [**MMSegmentation**](https://github.com/open-mmlab/mmsegmentation): OpenMMLab semantic segmentation toolbox and benchmark.
- [**MMOCR**](https://github.com/open-mmlab/mmocr): OpenMMLab text detection, recognition, and understanding toolbox.
- [**MMPose**](https://github.com/open-mmlab/mmpose): OpenMMLab pose estimation toolbox and benchmark.
- [**MMHuman3D**](https://github.com/open-mmlab/mmhuman3d): OpenMMLab 3D human parametric model toolbox and benchmark.
- [**MMSelfSup**](https://github.com/open-mmlab/mmselfsup): OpenMMLab self-supervised learning toolbox and benchmark.
- [**MMRazor**](https://github.com/open-mmlab/mmrazor): OpenMMLab model compression toolbox and benchmark.
- [**MMFewShot**](https://github.com/open-mmlab/mmfewshot): OpenMMLab fewshot learning toolbox and benchmark.
- [**MMAction2**](https://github.com/open-mmlab/mmaction2): OpenMMLab's next-generation action understanding toolbox and benchmark.
- [**MMTracking**](https://github.com/open-mmlab/mmtracking): OpenMMLab video perception toolbox and benchmark.
- [**MMFlow**](https://github.com/open-mmlab/mmflow): OpenMMLab optical flow toolbox and benchmark.
- [**MMEditing**](https://github.com/open-mmlab/mmediting): OpenMMLab image and video editing toolbox.
- [**MMGeneration**](https://github.com/open-mmlab/mmgeneration): OpenMMLab image and video generative models toolbox.
- [**MMDeploy**](https://github.com/open-mmlab/mmdeploy): OpenMMLab model deployment framework.
- [**MIM**](https://github.com/open-mmlab/mim): MIM installs OpenMMLab packages.
- [**MMEval**](https://github.com/open-mmlab/mmeval): OpenMMLab machine learning evaluation library.
- [**Playground**](https://github.com/open-mmlab/playground): A central hub for gathering and showcasing amazing projects built upon OpenMMLab.


